{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Week1_assignment_questions .ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/taniagupta21/Machine-Learning-Experiments/blob/master/Week1_assignment_questions_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "izcIED5qmAXn",
        "colab_type": "text"
      },
      "source": [
        "# Classifying Images of Clothing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJEbHssbmJFX",
        "colab_type": "text"
      },
      "source": [
        "In this tutorial, we'll build and train a neural network to classify images of clothing, like sneakers and shirts."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eu5r5kkjm5hT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import keras\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.utils import to_categorical\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vAPzZyl_mWEG",
        "colab_type": "text"
      },
      "source": [
        "## Import the Fashion MNIST dataset\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "894beOY3mWG-",
        "colab_type": "text"
      },
      "source": [
        "The Fashion MNIST dataset contains 70,000 grayscale images in 10 categories.\n",
        "Here, 60,000 images are used to train the network and 10,000 images to evaluate how accurately the network learned to classify images. You can access the Fashion MNIST directly from TensorFlow. Import and load the Fashion MNIST data directly from TensorFlow:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oj18DhGzu-OY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fashion_mnist = keras.datasets.fashion_mnist\n",
        "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n_vVmMkjmWRB",
        "colab_type": "text"
      },
      "source": [
        "The images are 28x28 NumPy arrays, with pixel values ranging from 0 to 255. The *labels* are an array of integers, ranging from 0 to 9. These correspond to the *class* of clothing the image represents:\n",
        "\n",
        "<table>\n",
        "  <tr>\n",
        "    <th>Label</th>\n",
        "    <th>Class</th>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>0</td>\n",
        "    <td>T-shirt/top</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>1</td>\n",
        "    <td>Trouser</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>2</td>\n",
        "    <td>Pullover</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>3</td>\n",
        "    <td>Dress</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>4</td>\n",
        "    <td>Coat</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>5</td>\n",
        "    <td>Sandal</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>6</td>\n",
        "    <td>Shirt</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>7</td>\n",
        "    <td>Sneaker</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>8</td>\n",
        "    <td>Bag</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>9</td>\n",
        "    <td>Ankle boot</td>\n",
        "  </tr>\n",
        "</table>\n",
        "\n",
        "Each image is mapped to a single label. Since the *class names* are not included with the dataset, store them here to use later when plotting the images:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZSPy1dsvg32",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
        "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_OOg8Vjova9u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(X_train.shape,X_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w1u6S5KlvckA",
        "colab_type": "text"
      },
      "source": [
        "## Preprocess the data\n",
        "\n",
        "The data must be preprocessed before training the network. If you inspect the first image in the training set, you will see that the pixel values fall in the range of 0 to 255:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T0IXZzNwwH4x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure()\n",
        "plt.imshow(X_train[0])\n",
        "plt.colorbar()\n",
        "plt.grid(False)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_XQZSlJ9vcoP",
        "colab_type": "text"
      },
      "source": [
        "Scale these values to a range of 0 to 1 before feeding them to the neural network model. To do so, divide the values by 255. It's important that the *training set* and the *testing set* be preprocessed in the same way:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DEdQzgK9Exsz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# flatten images into one-dimensional vector\n",
        "\n",
        "num_pixels = X_train.shape[1] * X_train.shape[2] # find size of one-dimensional vector\n",
        "\n",
        "X_train = X_train.reshape(X_train.shape[0], num_pixels).astype('float32') # flatten training images\n",
        "X_test = X_test.reshape(X_test.shape[0], num_pixels).astype('float32') # flatten test images\n",
        "print(X_train.shape,X_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9acvjcovvRt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train / 255.0\n",
        "X_test= X_test / 255.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QeZGbGVFwZ7u",
        "colab_type": "text"
      },
      "source": [
        "**Q1)** Why do we perform the process of Normalization and Standardization?\n",
        "\n",
        "\n",
        "a.   It makes gradient descent faster, but less accurate <br>\n",
        "b.   It makes gradient descent faster, and more accurate <br>\n",
        "c.   It reduces bias between different features which might have existed because of difference in order of magnitude. <br>\n",
        "d.   It does not affect the accuracy of the model <br>\n",
        " (more than one option might be correct) \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nWbKyexBP8GE",
        "colab_type": "text"
      },
      "source": [
        "Next we will apply one hot encoding on the labels\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arQpG_ASQFgJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n",
        "\n",
        "num_classes = y_test.shape[1]\n",
        "print(num_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ufh82_ld6iXn",
        "colab_type": "text"
      },
      "source": [
        "### your next task to build a model with the specifed architechture \n",
        "->input layer with relu activation function<br>\n",
        "->one hidden layer with 128 nodes and relu activation function<br>\n",
        "->ten output nodes with softmax activation function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xt3j7w01R5v1",
        "colab_type": "text"
      },
      "source": [
        "Now compile model with optimizer as adam and loss function as categorical crossentropy and metrics as accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1kFfx0vguIO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "#CODE\n",
        "# define classification model\n",
        "def classification_model():\n",
        "    # create model\n",
        "    model = Sequential()\n",
        "    model.add(Dense(num_pixels, activation='relu', input_shape=(num_pixels,)))\n",
        "    model.add(Dense(\"128\", activation='relu'))\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "    \n",
        "    \n",
        "    # compile model\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4k44zRZ9gs42",
        "colab_type": "text"
      },
      "source": [
        "###Training and Testing\n",
        "your task is to find the accuracy of the model testing dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AhJ0B2iigvpo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#CODE\n",
        "# build the model\n",
        "model = classification_model()\n",
        "# fit the model\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, verbose=2)\n",
        "# evaluate the model\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TMZvU0E-Nm8S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Accuracy: {}% \\n Error: {}'.format(scores[1], 1 - scores[1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mvWmS27agxHe",
        "colab_type": "text"
      },
      "source": [
        "**Q2)** You will find there is diffence in the training and test accuracy.what steps would you take to reduce this difference?<br>\n",
        "\n",
        "a) Increase the number of epochs<br>\n",
        "b) Increase the number of layers<br>\n",
        "c) Use the technique of dropout<br>\n",
        "d) Increase the amount of input data(given you have the luxury of generating more data)<br>\n",
        " (more than one option might be correct)\n",
        " \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "klpFIoY4D875",
        "colab_type": "text"
      },
      "source": [
        "### Now try to implement whatever you think will decrease the diffence between the training and test accuracy "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3EGM7S-KD4wj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#CODE\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2yJKvl8EEsZq",
        "colab_type": "text"
      },
      "source": [
        "**Q3)** One of the important step during neural network implementation is how initial the weights. What rule would give best result when you are initialising a **very deep neural network**?<br>\n",
        "a) To initialize very small values randomly.<br>\n",
        "b) To initialize randomly such that the mean of the activations should be zero.<br>\n",
        "c) To initialize randomly such that the variance of the activations should stay the same across every layer.<br>\n",
        "d) To initialize very big values randomly<br>\n",
        "(more than one option might be correct)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rK4BN2NQIZot",
        "colab_type": "text"
      },
      "source": [
        "### Now try to initialze the weights by the method you chose above and see whether your performance improves"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYCK1OJHD8RA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#CODE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DxTw5KTUyvNS",
        "colab_type": "text"
      },
      "source": [
        "### Thanks for completing the assignment, hope you liked it.\n",
        "(this assignment's solution will be provided in week 2)"
      ]
    }
  ]
}